{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e613dbed-67c6-44c7-9deb-8fed283eea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from keras.utils import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c1e2ab-c814-4b04-b64f-609863fb4ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('C:/Users/User/MLProjectTrails/grocery_ratings.csv')\n",
    "# Sort by date to ensure chronological order\n",
    "df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "df.sort_values(by=['reviewerID', 'date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dcc04a2-d139-4e79-af73-330a97e65fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df,seqlen):\n",
    "    user_groups = df.groupby('reviewerID')\n",
    "    X_train1, y_train1 = [], []\n",
    "    i = 0\n",
    "    for user, user_data in user_groups:\n",
    "        user_data = user_data.sort_values(by='date')\n",
    "        \n",
    "        # Check if the user has more than 5 interactions\n",
    "        if len(user_data) > seqlen:\n",
    "            i += 1\n",
    "            product_sequence = user_data['product_id'].values\n",
    "            rating_sequence = user_data['rating'].values\n",
    "            \n",
    "            # Append first 5 interactions to X_train\n",
    "            X_train1.append((product_sequence[:seqlen], rating_sequence[:seqlen]))\n",
    "            \n",
    "            # Append remaining interactions to y_train\n",
    "            y_train1.append((product_sequence[seqlen:], rating_sequence[seqlen:]))\n",
    "        \n",
    "        # Print progress every 100 users\n",
    "        if i % 10000 == 0:\n",
    "            print(f\"Processed {i} users\")\n",
    "    return X_train1, y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff7d13c-0abc-4a0c-b26c-1e67e1485ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa95e9d6-a673-4ae5-8ed2-2ffe47a2ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# Initialize the GroupShuffleSplit with a test size of 20% and random state for reproducibility\n",
    "gss = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
    "\n",
    "# Get the indices for train and test sets, grouping by 'reviewerID'\n",
    "train_idx, test_idx = next(gss.split(df, groups=df['reviewerID']))\n",
    "\n",
    "# Create train and test sets based on the indices\n",
    "train_df = df.iloc[train_idx]\n",
    "test_df = df.iloc[test_idx]\n",
    "\n",
    "# Verify the split: check that there is no overlap in reviewerIDs\n",
    "train_reviewers = set(train_df['reviewerID'])\n",
    "test_reviewers = set(test_df['reviewerID'])\n",
    "\n",
    "# Ensure there is no overlap\n",
    "assert len(train_reviewers.intersection(test_reviewers)) == 0, \"There is overlap between train and test reviewerIDs!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7b7852-50e4-43a8-add9-025f1f6dc486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000 users\n",
      "Processed 20000 users\n",
      "Processed 30000 users\n",
      "Processed 40000 users\n",
      "Processed 50000 users\n",
      "Processed 60000 users\n",
      "Processed 70000 users\n",
      "Processed 80000 users\n",
      "Processed 90000 users\n",
      "Processed 100000 users\n",
      "Processed 110000 users\n",
      "Processed 120000 users\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = process_data(train_df,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cb6589d-3e04-4328-bdf2-65afced43443",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_ids = df['product_id'].unique()\n",
    "product_id_map = {product_id: i+1 for i, product_id in enumerate(product_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccac6a10-476b-41bc-a721-6b336b9858cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finallprocess(X,y,seqlen):\n",
    "    #Convert product sequences in X to integer sequences\n",
    "    # as we require int in pad_sequences\n",
    "    X_mapped = [[product_id_map[prod] for prod in x[0]] for x in X]\n",
    "    \n",
    "    #Pad sequences to a length of seqlen\n",
    "    X_padded = pad_sequences(X_mapped, maxlen=seqlen)\n",
    "    \n",
    "    # Convert y to numpy array too\n",
    "    y = np.array([y[1][0] for y in y], dtype=np.float32)\n",
    "    return X_padded, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73965657-37b7-47a0-ab0f-943cc67cb01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded,y_train  = finallprocess(X_train, y_train,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff35aea3-125a-44b7-93a6-26eaf6b24d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "4033/4033 [==============================] - 862s 213ms/step - loss: 1.4909 - mae: 0.8776 - root_mean_squared_error: 1.2210\n",
      "Epoch 2/8\n",
      "4033/4033 [==============================] - 829s 205ms/step - loss: 1.0677 - mae: 0.7322 - root_mean_squared_error: 1.0333\n",
      "Epoch 3/8\n",
      "4033/4033 [==============================] - 827s 205ms/step - loss: 0.8436 - mae: 0.6149 - root_mean_squared_error: 0.9185\n",
      "Epoch 4/8\n",
      "4033/4033 [==============================] - 896s 222ms/step - loss: 0.7126 - mae: 0.5497 - root_mean_squared_error: 0.8442\n",
      "Epoch 5/8\n",
      "4033/4033 [==============================] - 891s 221ms/step - loss: 0.6280 - mae: 0.5050 - root_mean_squared_error: 0.7925\n",
      "Epoch 6/8\n",
      "4033/4033 [==============================] - 877s 218ms/step - loss: 0.5648 - mae: 0.4656 - root_mean_squared_error: 0.7515\n",
      "Epoch 7/8\n",
      "4033/4033 [==============================] - 824s 204ms/step - loss: 0.5126 - mae: 0.4369 - root_mean_squared_error: 0.7160\n",
      "Epoch 8/8\n",
      "4033/4033 [==============================] - 849s 210ms/step - loss: 0.4693 - mae: 0.4117 - root_mean_squared_error: 0.6851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e942284fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "# model.add(Embedding(input_dim=len(product_id_map) + 1, output_dim=50, input_length=5))  # +1 for padding index\n",
    "model.add(Embedding(input_dim=len(product_id_map) + 1, output_dim=50, input_length=2))\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(Dense(1))  # For regression (predicting rating)\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.compile(optimizer='nadam', loss=tensorflow.keras.losses.MeanSquaredError(), metrics=['mae', tensorflow.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_padded, y_train, epochs=8, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e0eca80-ee7a-460e-b93e-05520731945e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000 users\n",
      "Processed 20000 users\n",
      "Processed 30000 users\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = process_data(test_df,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "026a0447-41cc-4b13-adae-20cdc4c656b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded,y_test  = finallprocess(X_test, y_test,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bc44590-a963-4618-a641-d381d3989403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009/1009 [==============================] - 3s 3ms/step\n",
      "0.91787994\n"
     ]
    }
   ],
   "source": [
    "predicted_ratings = model.predict(X_test_padded)\n",
    "\n",
    "mae = mean_absolute_error(y_test,predicted_ratings)\n",
    "print(mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "988c60e7-3d53-4790-a813-8a852710b7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.2851907\n"
     ]
    }
   ],
   "source": [
    "rmse = mean_squared_error(y_test, predicted_ratings, squared=False)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f937ecc7-71f9-44b7-b576-54ee84a30fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296604, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93e43830-5c15-479e-be3c-8d4b01438b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1188893, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f38643e4-7d15-402d-988e-a0465c91c447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32261,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['reviewerID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6f8549e-cea9-43e1-a0b7-6d79aa21cc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129041,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['reviewerID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c47c0ad8-5465-4f8e-ab2e-94c548ba1e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161302,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviewerID'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8205549-718c-4ce4-bb69-1c2533a01db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
